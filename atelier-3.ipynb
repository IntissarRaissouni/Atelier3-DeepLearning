{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14210191,"sourceType":"datasetVersion","datasetId":9063975}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/input/arabic-cybersecurity-texts/arabic_cybersecurity_texts.csv\")\ndf.head()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:22:52.994341Z","iopub.execute_input":"2025-12-18T11:22:52.994873Z","iopub.status.idle":"2025-12-18T11:22:53.326985Z","shell.execute_reply.started":"2025-12-18T11:22:52.994825Z","shell.execute_reply":"2025-12-18T11:22:53.326329Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                                Text  Score\n0  إذا كانت بيئة العمل لا تستند إلى نظام تشغيل آم...    9.5\n1  احتمال أن يشكل تهديدا سوف تستخدم من التعرض للض...    8.9\n2  برمجيات خبيثةأيضا في بعض الأحيانالبرامج الضارة...    5.2\n3  من الأساليب الشائعة بشكل متزايد (2015) برامج ا...    2.4\n4  وبالأستناد إلى نتائج المشروع المشترك لمعهد الم...    2.1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>إذا كانت بيئة العمل لا تستند إلى نظام تشغيل آم...</td>\n      <td>9.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>احتمال أن يشكل تهديدا سوف تستخدم من التعرض للض...</td>\n      <td>8.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>برمجيات خبيثةأيضا في بعض الأحيانالبرامج الضارة...</td>\n      <td>5.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>من الأساليب الشائعة بشكل متزايد (2015) برامج ا...</td>\n      <td>2.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>وبالأستناد إلى نتائج المشروع المشترك لمعهد الم...</td>\n      <td>2.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import re\n\ndef clean_arabic(text):\n    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)   # keep Arabic only\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndf[\"Clean_Text\"] = df[\"Text\"].apply(clean_arabic)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:22:53.328271Z","iopub.execute_input":"2025-12-18T11:22:53.328532Z","iopub.status.idle":"2025-12-18T11:22:53.342375Z","shell.execute_reply.started":"2025-12-18T11:22:53.328510Z","shell.execute_reply":"2025-12-18T11:22:53.341649Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                Text  Score  \\\n0  إذا كانت بيئة العمل لا تستند إلى نظام تشغيل آم...    9.5   \n1  احتمال أن يشكل تهديدا سوف تستخدم من التعرض للض...    8.9   \n2  برمجيات خبيثةأيضا في بعض الأحيانالبرامج الضارة...    5.2   \n3  من الأساليب الشائعة بشكل متزايد (2015) برامج ا...    2.4   \n4  وبالأستناد إلى نتائج المشروع المشترك لمعهد الم...    2.1   \n\n                                          Clean_Text  \n0  إذا كانت بيئة العمل لا تستند إلى نظام تشغيل آم...  \n1  احتمال أن يشكل تهديدا سوف تستخدم من التعرض للض...  \n2  برمجيات خبيثةأيضا في بعض الأحيانالبرامج الضارة...  \n3  من الأساليب الشائعة بشكل متزايد برامج الإعلانا...  \n4  وبالأستناد إلى نتائج المشروع المشترك لمعهد الم...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Score</th>\n      <th>Clean_Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>إذا كانت بيئة العمل لا تستند إلى نظام تشغيل آم...</td>\n      <td>9.5</td>\n      <td>إذا كانت بيئة العمل لا تستند إلى نظام تشغيل آم...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>احتمال أن يشكل تهديدا سوف تستخدم من التعرض للض...</td>\n      <td>8.9</td>\n      <td>احتمال أن يشكل تهديدا سوف تستخدم من التعرض للض...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>برمجيات خبيثةأيضا في بعض الأحيانالبرامج الضارة...</td>\n      <td>5.2</td>\n      <td>برمجيات خبيثةأيضا في بعض الأحيانالبرامج الضارة...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>من الأساليب الشائعة بشكل متزايد (2015) برامج ا...</td>\n      <td>2.4</td>\n      <td>من الأساليب الشائعة بشكل متزايد برامج الإعلانا...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>وبالأستناد إلى نتائج المشروع المشترك لمعهد الم...</td>\n      <td>2.1</td>\n      <td>وبالأستناد إلى نتائج المشروع المشترك لمعهد الم...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\nMAX_WORDS = 10000\nMAX_LEN = 100\n\ntokenizer = Tokenizer(num_words=MAX_WORDS)\ntokenizer.fit_on_texts(df[\"Clean_Text\"])\n\nsequences = tokenizer.texts_to_sequences(df[\"Clean_Text\"])\nX = pad_sequences(sequences, maxlen=MAX_LEN)\n\ny = df[\"Score\"].values\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:22:53.343289Z","iopub.execute_input":"2025-12-18T11:22:53.343587Z","iopub.status.idle":"2025-12-18T11:23:08.253996Z","shell.execute_reply.started":"2025-12-18T11:22:53.343565Z","shell.execute_reply":"2025-12-18T11:23:08.253366Z"}},"outputs":[{"name":"stderr","text":"2025-12-18 11:22:55.088173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766056975.287713      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766056975.342338      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766056975.812951      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766056975.812992      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766056975.812995      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766056975.812997      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nprint(X_train.shape, X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:23:08.255424Z","iopub.execute_input":"2025-12-18T11:23:08.255964Z","iopub.status.idle":"2025-12-18T11:23:08.384133Z","shell.execute_reply.started":"2025-12-18T11:23:08.255939Z","shell.execute_reply":"2025-12-18T11:23:08.383444Z"}},"outputs":[{"name":"stdout","text":"(115, 100) (29, 100)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nX_train_t = torch.tensor(X_train, dtype=torch.long)\nX_test_t  = torch.tensor(X_test, dtype=torch.long)\n\ny_train_t = torch.tensor(y_train, dtype=torch.float32)\ny_test_t  = torch.tensor(y_test, dtype=torch.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:23:08.384932Z","iopub.execute_input":"2025-12-18T11:23:08.385364Z","iopub.status.idle":"2025-12-18T11:23:12.291908Z","shell.execute_reply.started":"2025-12-18T11:23:08.385339Z","shell.execute_reply":"2025-12-18T11:23:12.291219Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:23:12.292743Z","iopub.execute_input":"2025-12-18T11:23:12.292996Z","iopub.status.idle":"2025-12-18T11:23:12.297643Z","shell.execute_reply.started":"2025-12-18T11:23:12.292974Z","shell.execute_reply":"2025-12-18T11:23:12.296878Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"BATCH_SIZE = 16\n\ntrain_dataset = TextDataset(X_train_t, y_train_t)\ntest_dataset  = TextDataset(X_test_t, y_test_t)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:23:12.298514Z","iopub.execute_input":"2025-12-18T11:23:12.298712Z","iopub.status.idle":"2025-12-18T11:23:12.310838Z","shell.execute_reply.started":"2025-12-18T11:23:12.298693Z","shell.execute_reply":"2025-12-18T11:23:12.310164Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"xb, yb = next(iter(train_loader))\nprint(xb.shape, yb.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:23:12.311719Z","iopub.execute_input":"2025-12-18T11:23:12.312177Z","iopub.status.idle":"2025-12-18T11:23:12.355791Z","shell.execute_reply.started":"2025-12-18T11:23:12.312155Z","shell.execute_reply":"2025-12-18T11:23:12.355240Z"}},"outputs":[{"name":"stdout","text":"torch.Size([16, 100]) torch.Size([16])\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch.nn as nn\n\nclass LSTMModel(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, 1)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        _, (h, _) = self.lstm(x)\n        out = self.fc(h[-1])\n        return out.squeeze()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:23:12.356506Z","iopub.execute_input":"2025-12-18T11:23:12.356768Z","iopub.status.idle":"2025-12-18T11:23:12.361833Z","shell.execute_reply.started":"2025-12-18T11:23:12.356747Z","shell.execute_reply":"2025-12-18T11:23:12.361181Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"VOCAB_SIZE = MAX_WORDS\nEMBED_DIM = 128\nHIDDEN_DIM = 64\n\nmodel = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:23:23.879413Z","iopub.execute_input":"2025-12-18T11:23:23.879972Z","iopub.status.idle":"2025-12-18T11:23:26.691982Z","shell.execute_reply.started":"2025-12-18T11:23:23.879942Z","shell.execute_reply":"2025-12-18T11:23:26.691364Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"EPOCHS = 10\n\nfor epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0\n\n    for xb, yb in train_loader:\n        optimizer.zero_grad()\n        preds = model(xb)\n        loss = criterion(preds, yb)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch [{epoch+1}/{EPOCHS}] - Loss: {avg_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:23:33.606016Z","iopub.execute_input":"2025-12-18T11:23:33.606985Z","iopub.status.idle":"2025-12-18T11:23:35.045304Z","shell.execute_reply.started":"2025-12-18T11:23:33.606951Z","shell.execute_reply":"2025-12-18T11:23:35.044134Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] - Loss: 32.2294\nEpoch [2/10] - Loss: 28.9638\nEpoch [3/10] - Loss: 25.7435\nEpoch [4/10] - Loss: 26.0406\nEpoch [5/10] - Loss: 21.7397\nEpoch [6/10] - Loss: 11.5885\nEpoch [7/10] - Loss: 8.1794\nEpoch [8/10] - Loss: 8.3451\nEpoch [9/10] - Loss: 7.9673\nEpoch [10/10] - Loss: 7.6731\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model.eval()\npreds_list = []\ntrue_list = []\n\nwith torch.no_grad():\n    for xb, yb in test_loader:\n        preds = model(xb)\n        preds_list.extend(preds.numpy())\n        true_list.extend(yb.numpy())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:23:50.734534Z","iopub.execute_input":"2025-12-18T11:23:50.735437Z","iopub.status.idle":"2025-12-18T11:23:50.758594Z","shell.execute_reply.started":"2025-12-18T11:23:50.735399Z","shell.execute_reply":"2025-12-18T11:23:50.757890Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error\nimport numpy as np\n\nmse = mean_squared_error(true_list, preds_list)\nrmse = np.sqrt(mse)\nmae = mean_absolute_error(true_list, preds_list)\n\nprint(\"MSE :\", mse)\nprint(\"RMSE:\", rmse)\nprint(\"MAE :\", mae)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:23:56.992141Z","iopub.execute_input":"2025-12-18T11:23:56.992910Z","iopub.status.idle":"2025-12-18T11:23:56.999592Z","shell.execute_reply.started":"2025-12-18T11:23:56.992877Z","shell.execute_reply":"2025-12-18T11:23:56.998549Z"}},"outputs":[{"name":"stdout","text":"MSE : 9.814581711168664\nRMSE: 3.132823281190413\nMAE : 2.7177101543237425\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import torch.nn as nn\n\nclass GRUModel(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, 1)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        _, h = self.gru(x)          # h: (1, batch, hidden)\n        out = self.fc(h[-1])\n        return out.squeeze()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:30:08.264777Z","iopub.execute_input":"2025-12-18T11:30:08.265638Z","iopub.status.idle":"2025-12-18T11:30:08.271057Z","shell.execute_reply.started":"2025-12-18T11:30:08.265607Z","shell.execute_reply":"2025-12-18T11:30:08.270367Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"VOCAB_SIZE = MAX_WORDS\nEMBED_DIM = 128\nHIDDEN_DIM = 64\n\ngru_model = GRUModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(gru_model.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:30:14.342556Z","iopub.execute_input":"2025-12-18T11:30:14.343157Z","iopub.status.idle":"2025-12-18T11:30:14.357712Z","shell.execute_reply.started":"2025-12-18T11:30:14.343129Z","shell.execute_reply":"2025-12-18T11:30:14.357074Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"EPOCHS = 10\n\nfor epoch in range(EPOCHS):\n    gru_model.train()\n    total_loss = 0\n\n    for xb, yb in train_loader:\n        optimizer.zero_grad()\n        preds = gru_model(xb)\n        loss = criterion(preds, yb)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"GRU Epoch [{epoch+1}/{EPOCHS}] - Loss: {avg_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:30:20.313347Z","iopub.execute_input":"2025-12-18T11:30:20.313949Z","iopub.status.idle":"2025-12-18T11:30:23.763846Z","shell.execute_reply.started":"2025-12-18T11:30:20.313917Z","shell.execute_reply":"2025-12-18T11:30:23.763055Z"}},"outputs":[{"name":"stdout","text":"GRU Epoch [1/10] - Loss: 31.3884\nGRU Epoch [2/10] - Loss: 30.4850\nGRU Epoch [3/10] - Loss: 26.9185\nGRU Epoch [4/10] - Loss: 24.0528\nGRU Epoch [5/10] - Loss: 16.7767\nGRU Epoch [6/10] - Loss: 9.3798\nGRU Epoch [7/10] - Loss: 8.0451\nGRU Epoch [8/10] - Loss: 7.7911\nGRU Epoch [9/10] - Loss: 7.7377\nGRU Epoch [10/10] - Loss: 7.1807\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"gru_model.eval()\npreds_list = []\ntrue_list = []\n\nwith torch.no_grad():\n    for xb, yb in test_loader:\n        preds = gru_model(xb)\n        preds_list.extend(preds.numpy())\n        true_list.extend(yb.numpy())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:30:29.882225Z","iopub.execute_input":"2025-12-18T11:30:29.882542Z","iopub.status.idle":"2025-12-18T11:30:29.903600Z","shell.execute_reply.started":"2025-12-18T11:30:29.882515Z","shell.execute_reply":"2025-12-18T11:30:29.902816Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error\nimport numpy as np\n\nmse_gru = mean_squared_error(true_list, preds_list)\nrmse_gru = np.sqrt(mse_gru)\nmae_gru = mean_absolute_error(true_list, preds_list)\n\nprint(\"GRU MSE :\", mse_gru)\nprint(\"GRU RMSE:\", rmse_gru)\nprint(\"GRU MAE :\", mae_gru)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:30:35.238402Z","iopub.execute_input":"2025-12-18T11:30:35.239305Z","iopub.status.idle":"2025-12-18T11:30:35.245867Z","shell.execute_reply.started":"2025-12-18T11:30:35.239260Z","shell.execute_reply":"2025-12-18T11:30:35.245060Z"}},"outputs":[{"name":"stdout","text":"GRU MSE : 10.133272044264933\nGRU RMSE: 3.1832800763151416\nGRU MAE : 2.7647724773349434\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import pandas as pd\n\nresults = pd.DataFrame({\n    \"Model\": [\"LSTM\", \"GRU\"],\n    \"MAE\": [mae, mae_gru],\n    \"RMSE\": [rmse, rmse_gru],\n    \"MSE\": [mse, mse_gru]\n})\n\nresults\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:30:45.252695Z","iopub.execute_input":"2025-12-18T11:30:45.253341Z","iopub.status.idle":"2025-12-18T11:30:45.262993Z","shell.execute_reply.started":"2025-12-18T11:30:45.253304Z","shell.execute_reply":"2025-12-18T11:30:45.262254Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"  Model       MAE      RMSE        MSE\n0  LSTM  2.717710  3.132823   9.814582\n1   GRU  2.764772  3.183280  10.133272","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>MAE</th>\n      <th>RMSE</th>\n      <th>MSE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LSTM</td>\n      <td>2.717710</td>\n      <td>3.132823</td>\n      <td>9.814582</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GRU</td>\n      <td>2.764772</td>\n      <td>3.183280</td>\n      <td>10.133272</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"**2ème partie :**","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:32:18.373473Z","iopub.execute_input":"2025-12-18T11:32:18.374162Z","iopub.status.idle":"2025-12-18T11:32:22.721908Z","shell.execute_reply.started":"2025-12-18T11:32:18.374129Z","shell.execute_reply":"2025-12-18T11:32:22.721190Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel\n\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n\ntokenizer.pad_token = tokenizer.eos_token\nmodel.resize_token_embeddings(len(tokenizer))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:32:24.445722Z","iopub.execute_input":"2025-12-18T11:32:24.446612Z","iopub.status.idle":"2025-12-18T11:32:34.359364Z","shell.execute_reply.started":"2025-12-18T11:32:24.446564Z","shell.execute_reply":"2025-12-18T11:32:34.358623Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4901d4d25a2d42f8a4d44e21ac65f4c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cabb841655f4c9caddabf5dd1c53d37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48bfd96da2474cda99e08533e730df32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c120d3be10564b6388a6578126121e0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ccdcab735bb4012a4593318663b1e8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2892c28923a74459be3cc278bdb4ad25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bec8992e59f4dc3bf0c8ea2407261bd"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Embedding(50257, 768)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"texts = [\n    \"Cybersecurity is an important field in modern information systems.\",\n    \"Deep learning models are widely used for text analysis.\",\n    \"Transformers have revolutionized natural language processing.\",\n    \"GPT models can generate coherent and meaningful text.\",\n    \"Data security is a major challenge in the digital world.\"\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:32:45.081448Z","iopub.execute_input":"2025-12-18T11:32:45.082539Z","iopub.status.idle":"2025-12-18T11:32:45.086083Z","shell.execute_reply.started":"2025-12-18T11:32:45.082505Z","shell.execute_reply":"2025-12-18T11:32:45.085270Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport torch\n\nclass TextDataset(Dataset):\n    def __init__(self, texts, tokenizer, max_len=64):\n        self.encodings = tokenizer(\n            texts,\n            truncation=True,\n            padding=True,\n            max_length=max_len,\n            return_tensors=\"pt\"\n        )\n\n    def __len__(self):\n        return self.encodings[\"input_ids\"].size(0)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": self.encodings[\"input_ids\"][idx],\n            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n            \"labels\": self.encodings[\"input_ids\"][idx]\n        }\n\ndataset = TextDataset(texts, tokenizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:32:51.329308Z","iopub.execute_input":"2025-12-18T11:32:51.330044Z","iopub.status.idle":"2025-12-18T11:32:51.338517Z","shell.execute_reply.started":"2025-12-18T11:32:51.330013Z","shell.execute_reply":"2025-12-18T11:32:51.337983Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./gpt2-finetuned\",\n    num_train_epochs=3,\n    per_device_train_batch_size=2,\n    logging_steps=10,\n    save_steps=100,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:32:58.242006Z","iopub.execute_input":"2025-12-18T11:32:58.242320Z","iopub.status.idle":"2025-12-18T11:33:06.215405Z","shell.execute_reply.started":"2025-12-18T11:32:58.242292Z","shell.execute_reply":"2025-12-18T11:33:06.214672Z"}},"outputs":[{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6, training_loss=4.76703421274821, metrics={'train_runtime': 4.5442, 'train_samples_per_second': 3.301, 'train_steps_per_second': 1.32, 'total_flos': 91860480000.0, 'train_loss': 4.76703421274821, 'epoch': 3.0})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"import torch\n\n# mettre le modèle en mode évaluation\nmodel.eval()\n\n# choisir le device du modèle\ndevice = model.device\n\nprompt = \"Cybersecurity is\"\n\n# tokenization AVEC attention mask\ninputs = tokenizer(\n    prompt,\n    return_tensors=\"pt\",\n    padding=True\n)\n\n# déplacer les tensors sur le même device que le modèle\ninput_ids = inputs[\"input_ids\"].to(device)\nattention_mask = inputs[\"attention_mask\"].to(device)\n\n# génération\nwith torch.no_grad():\n    output = model.generate(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n        max_length=60,\n        do_sample=True,\n        top_k=50,\n        top_p=0.95,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n# décodage\ngenerated_text = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(generated_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T11:34:59.245496Z","iopub.execute_input":"2025-12-18T11:34:59.246181Z","iopub.status.idle":"2025-12-18T11:34:59.787643Z","shell.execute_reply.started":"2025-12-18T11:34:59.246152Z","shell.execute_reply":"2025-12-18T11:34:59.786873Z"}},"outputs":[{"name":"stdout","text":"Cybersecurity is the fundamental concept behind the Internet, and the future is not just about government control of the Internet.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}